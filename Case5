import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.metrics import BinaryAccuracy
np.random.seed(42)
tf.random.set_seed(42)
X = np.array([[0,0],
              [0,1],
              [1,0],
              [1,1]], dtype=np.float32)
y = np.array([[0],
              [1],
              [1],
              [0]], dtype=np.float32)
model = Sequential([
    Dense(4, activation='tanh', input_shape=(2,)),   
    Dense(1, activation='sigmoid')                  
])
model.compile(optimizer=Adam(learning_rate=0.1),
              loss=BinaryCrossentropy(),
              metrics=[BinaryAccuracy(threshold=0.5)])
model.summary()
history = model.fit(X, y, epochs=500, verbose=0)
loss, acc = model.evaluate(X, y, verbose=0)
print(f"\nFinal training loss: {loss:.4f}, accuracy: {acc:.4f}\n")
pred_probs = model.predict(X)
preds = (pred_probs >= 0.5).astype(int)
print("Input\t\tPredProb\tPred\tExpected")
for i, inp in enumerate(X):
    print(f"{inp.tolist()}\t{pred_probs[i,0]:.4f}\t\t{preds[i,0]}\t{int(y[i,0])}")
try:
    import matplotlib.pyplot as plt
    grid_x = np.linspace(-0.5, 1.5, 200)
    grid_y = np.linspace(-0.5, 1.5, 200)
    gx, gy = np.meshgrid(grid_x, grid_y)
    XY = np.c_[gx.ravel(), gy.ravel()]
    probs = model.predict(XY, verbose=0).reshape(gx.shape)
    plt.contourf(gx, gy, probs, levels=50, alpha=0.8)
    plt.colorbar(label='P(XOR=1)')
    plt.scatter(X[:,0], X[:,1], c=y.ravel(), edgecolor='k', s=120, cmap='bwr')
    for i, pt in enumerate(X):
        plt.text(pt[0]+0.03, pt[1]+0.03, f"{int(y[i,0])}", fontsize=12)
    plt.title('MLP decision surface for XOR')
    plt.xlabel('Input A')
    plt.ylabel('Input B')
    plt.xlim(-0.5,1.5); plt.ylim(-0.5,1.5)
    plt.show()
except Exception:
    pass